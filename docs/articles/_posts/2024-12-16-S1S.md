---
layout: post
title: Monadic Second Order theory of One's Successor
truncated_preview: true
excerpt_separator: <!--more-->
tags:
  - miscellaneous
categories: article
---
<!--more-->
Partiamo con il dire perchè c'è bisogno di capire:
- la monadic second order theory of one's successor (S1S)
- la relazione tra automi di Büchi e S1S

Onestamente ancora non la so nemmeno io, quindi qua ci metto un bel #todo e appena lo scopro lo scrivo

Prima cosa da imparare: che cosa sarebbe un linguaggio del $S1S_\cal{A}$?

----------------------------------
Un linguaggio $S1S_{\cal{A}}$ è un linguaggio composto a partire da:
- **termini**: 
	praticamente sarebbero i simboli di costante costruiti a partire da 0 e usando la funzione successore (+1) e le variabili $x,y,...$ (su cui possono essere applicate le funzioni successore)
- **formule atomiche**:
	si formano a partire dai termini e possono essere nelle forme (con $t_{1}$ e $t_{2}$ due termini) 
	- $t_{1}=t_{2}$
	- $t_{1}<t_{2}$
	- $t_1 \in X$ con X una variabile al second'ordine
	- $t_{1} \in Q_a$ con Q  simbolo di predicato unario (uno per ogni $a \in A$)
- **formule:** 
	possono comparire quantificatori $\forall, \exists$ e operatori booleani come $\lnot,\wedge,\lor$ applicati su variabili individuali o variabili insiemistiche ($\forall x$ o $\forall X$)

----------------------------------

**formula chiusa (enunciato)**: una formula priva di variabili libere


***! Osservazione***:
la definizione del simbolo 0 e del predicato < non è necessario in S1S. Difatti è sufficiente usare l'operatore successore e la logica del second'ordine:
- lo zero può essere definito come 

$$
\forall y(x<y \lor x=y) 
$$

oppure (senza predicato <)

$$
\lnot \exists y(y+1=x)
$$

- il predicato < può essere riscritto come	

$$
\forall X(x+1 \in X \land \forall z(z\in X \to z+1 \in X)\to y \in X)
$$
			
### Come rappresento una $\omega$-parola usando la logica?
Semplicemente creiamo una sorta di "stampino" $\underline{\alpha}$ definito come 

$$\underline{\alpha} = <\omega, 0,+1,<,\{Q_{a}\}_{a \in A}>$$
dove il dominio $\omega$ corrisponde ai naturali e $Q_a$ è definito come l'insieme degli indici delle posizioni della $\omega$-parola $\alpha$ in cui il simbolo è $a$

$$
Q_{a} = \{i \in \omega \; | \; \alpha(i) = a\}
$$

### Come rappresento un linguaggio usando delle parole S1S?
È possibile definire un linguaggio a partire da una formula logica che dev'essere soddisfatta da ogni $\omega$-parola.
In particolare data una formula $\varphi$, il linguaggio descritto da tale formula è definito come

$$
L(\varphi) = \{\alpha \in A\; |\; \alpha \models \varphi \}
$$

Facciamo degli esempi:

1. Sia L il linguaggio sull’alfabeto $\{a, b, c\}$ che contiene tutte e sole le $\omega$-parole tali che ogni occorrenza del simbolo $a$ sia seguita da un’occorrenza del simbolo $b$. $L$ è catturato dal seguente enunciato al prim’ordine:

$$
\varphi = \forall i (x\in Q_{a} \to \exists j(i<j \land j \in Q_{b}))
$$

2. Sia L il linguaggio sull’alfabeto $\{a, b, c\}$ che contiene tutte e sole le $\omega$-parole tali che tra ogni coppia di occorrenze successive del simbolo $a$ vi sia un numero pari di occorrenze dei simboli b e c. L è catturato dal seguente enunciato al second’ordine:

$$
\varphi = \forall i,j((i \in Q_{a}\land j\in Q_{a} \land i<j) \land \lnot \exists z (z <j \land z<i \land z \in Q_{a}) \to \exists X(x \in X \land \forall (z \in X \iff z+1 \not\in X) \land y \not\in X))
$$
la clausola

$$
\lnot \exists z (z <j \land z<i \land z \in Q_{a})
$$
serve per escludere che siano presenti simboli $a$ tra altri due simboli $a$. L'ultima implicazione invece controlla la parità.


La cosa interessante è che possiamo fare in modo di rendere irrilevante l'alfabeto usato. Come? Semplicemente convertendo ogni simbolo in A nella corrispettiva codifica binaria
(ad esempio se A={a,b,c,d} posso considerare il nuovo alfabeto $A' = {0,1}^n$ con $n = log(|A|))$.
e ricreando l'insieme $Q_{a}$ in un nuovo insieme definito come 

$$
P_{k} = \{ i \in \omega \; | \; (\alpha(i)_{k}) = 1\}
$$

A questo punto quindi diventa anche più facile definire il linguaggio L a partire da una formula S1S $\varphi$ 

$$
L(\varphi) = \{\alpha \in ({0,1}^n)^\omega \; | \; \alpha \models \varphi(X_{1}, \dots, X_{n}) \}
$$
#### $S1S_\cal{A}$ vs $S1S$
Qualcuno potrebbe aver obiettato dicendo "ma perchè hai scritto $S1S_\cal{A}$ invece di $S1S$? Sono sinonimi?". La risposta è NO. 
$S1S_\cal{A}$ si riferisce a una Second-order Monadic Logic of Successor che lavora su $\omega$-parole costruite su un alfabeto $A$. 

S1S invece si riferisce alla versione "generica" che non fa uso di un alfabeto, ma di indici delle lettere dell'alfabeto (quella traduzione che avevamo visto prima). A questo punto quindi le lettere dell'alfabeto vengono sostituite da variabili del second'ordine che rappresentano l'insieme di posizioni associate ai simboli dell'alfabeto di partenza.

### Lemma: Chiusura per proiezione
Sia data la formula S1S 

$$
\psi(X_{1}, \dots, X_{i-1}, X_{i+1}, \dots, X_{n}) = \exists X_{i}\varphi(X_{1},\dots,X_{n})$$

Se $L(\varphi)$ è $\omega$-regolare, allora anche $L(\psi)$ è $\omega$-regolare.
!Occhio perchè nella formula $\psi$ bisogna osservare che tra le variabili di second'ordine espresse come argomento manca la variabile $X_{i}$ 

**Che significa questa cosa?** 
Il lemma dice una cosa importante. Dice che se ho una formula $\psi$ che opera su $n$ variabili del second'ordine, posso sempre riuscire a ridurre il numero di variabili usate mediante una riscrittura della formula rimanendo comunque all'interno del potere espressivo di S1S. Perciò se posso esprimere mediante una formula S1S un certo linguaggio che usa n variabili, posso fare lo stesso anche con una formula che ne usa meno di n.

Ad esempio se consideriamo $A = \{a, b, c\}$ e un linguaggio $L \subseteq A^\omega$ definito da:  
"Ogni occorrenza di a è seguita da un b prima di un c".

La formula in S1S per L è:

$$
\forall x. (x \in X_a \implies \exists y. (y > x \land y \in X_b \land \forall z. (x < z < y \implies z \notin X_c)))
$$

Se ora vogliamo proiettare L sull'alfabeto $B = \{a, c\}$ eliminando $b$, il nuovo linguaggio $\pi(L)$ richiede una nuova formula che verifica implicitamente la condizione rimossa.

La nuova formula potrebbe essere:

$$
\forall x. (x \in X_a \implies \exists y. (y > x \land y \in X_c))
$$
Questo dimostra che possiamo tradurre la proiezione in una nuova formula S1S.

**Dimostrazione**
L'idea è dimostrare che a partire da un automa di Büchi $\cal{A}$ sull'alfabeto $\{0,1\}^n$ che riconosce un linguaggio $L(\varphi)$ è possibile generare un automa di Büchi $\cal{A}'$ che riconosce il linguaggio $L(\psi)$ sull'alfabeto $\{0,1\}^{n-1}$.
Se tale automa esiste sappiamo che anche il linguaggio $L(\psi)$ è $\omega$-regolare.

L'automa $\cal{A}'$ viene costruito considerando l'automa $\cal{A}$ e rimpiazzando ogni simbolo $(j_{1},\dots,j_{i},\dots,j_{n})$ con un nuovo simbolo $( j_{1},\dots,j_{i-1}, j_{i+1},\dots ,j_{n})$. 
In pratica non si fa altro che ridurre la codifica dei simboli.
Una parola $\alpha = ( \alpha_{1},\dots,\alpha_{i-1}, \alpha_{i+1},\dots ,\alpha_{n})$ è accettata da $\cal{A}'$ se e solo se esiste una componente $\beta$ tale che $\alpha' = ( \alpha_{1},\dots,\alpha_{i-1}, \beta, \alpha_{i+1},\dots ,\alpha_{n})$ è accettata da $\cal{A}$.



### Possibili domande
Che differenza c'è tra monadic second order theory of one's successor e monadic first order theory of one's successor?

###### 1. **Linguaggio con occorrenza obbligatoria**

Definisci un enunciato che cattura il linguaggio delle $\omega$-parole sull’alfabeto $\{a,b,c\}$ in cui ogni simbolo c è preceduto da almeno un simbolo b.

---

###### 2. **Parità delle occorrenze**

Definisci un enunciato per il linguaggio di $\omega$-parole sull’alfabeto $\{0,1\}$ in cui ogni prefisso finito della parola contiene un numero pari di occorrenze del simbolo 1.

---

###### 3. **Evento ciclico**

Trova l’enunciato che descrive il linguaggio delle $\omega$-parole sull’alfabeto $\{x, y, z\}$ in cui il simbolo x appare infinitamente spesso e ogni occorrenza di x è seguita (prima o poi) da un’ulteriore occorrenza di y.

---

###### 4. **Alternanza tra simboli**

Definisci un enunciato per il linguaggio delle $\omega$-parole sull'alfabeto $\{a, b\}$ in cui a e b compaiono in modo alternato, senza che ci siano due a o due b consecutivi.

---

###### 5. **Suffisso infinito**

Definisci il linguaggio delle ω\omegaω-parole sull'alfabeto $\{p, q, r\}$ in cui, a partire da un certo punto della parola, appaiono solo i simboli p e q.

---

###### 6. **Mai ripetizione consecutiva**

Trova l’enunciato per il linguaggio delle $\omega$-parole sull’alfabeto $\{a, b\}$ in cui il simbolo a non compare mai due volte consecutive.

---

###### 7. **Prefissi validi**

Definisci un linguaggio L sull’alfabeto $\{0, 1, 2\}$ in cui ogni prefisso finito di una parola $\alpha$ ha almeno tante occorrenze del simbolo 0 quante del simbolo 1.

---

###### 8. **Eventuale periodicità**

Trova l’enunciato che descrive le $\omega$-parole sull’alfabeto $\{a, b\}$ che a partire da un certo punto diventano periodiche con il ciclo ab.

---

###### 9. **Posizioni specifiche**

Definisci un linguaggio L sull’alfabeto $\{x, y, z\}$ in cui le occorrenze di x appaiono solo in posizioni pari.

---

###### 10. **Infinitamente molti simboli**

Trova l’enunciato che descrive le $\omega$-parole sull’alfabeto $\{a, b, c\}$ in cui appaiono infinitamente molte b e c, ma solo un numero finito di a.

---

### Consigli per la risoluzione

1. **Strategia generale**: Dividi il problema in sotto-obiettivi logici (es., "ogni a è seguito da un b").
2. **Usa variabili monadiche**:
    - Per definire insiemi di posizioni (X,Y,Z,…X, Y, Z, \dotsX,Y,Z,…).
    - Per catturare proprietà globali o locali (es., periodicità, occorrenze infinite).
3. **Costruisci passo per passo**: Parti da formule base (es., "il simbolo a compare in una certa posizione") e componile per ottenere la formula finale.